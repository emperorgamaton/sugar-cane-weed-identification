# -*- coding: utf-8 -*-
"""Weed Identification (2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t3yzxWsZ3Vd0ms9HG1x3ViFsiTaG9VGD

#Data Preparation
"""

# from google.colab import drive
# drive.mount('/content/drive')

import argparse
import os
from zipfile import ZipFile
from urllib.request import urlopen
import shutil
import pandas as pd
from time import time
from datetime import datetime
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger
from tensorflow.keras.optimizers import Adam
import csv
from keras.models import Model, load_model
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
from keras import backend as K
from skimage.io import imread
from skimage.transform import resize
from keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.resnet50 import ResNet50
from keras.layers import Dense, GlobalAveragePooling2D
import requests
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.utils import plot_model
from tensorflow.keras import layers
from tensorflow.keras.optimizers import RMSprop

# zip_ref = ZipFile('/content/drive/MyDrive/images.zip', 'r') #Opens the zip file in read mode
# zip_ref.extractall('/content/drive/MyDrive') #Extracts the files into the /tmp folder
# zip_ref.close()

RAW_IMG_SIZE = (256, 256)
IMG_SIZE = (150, 150)
BATCH_SIZE = 32
img_height = 150
img_width = 150
INPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)
MAX_EPOCH = 200
FOLDS = 5
STOPPING_PATIENCE = 32
LR_PATIENCE = 16
INITIAL_LR = 0.0001

IMG_DIRECTORY = "/images/images"

#tf.keras.preprocessing.image.ImageDataGenerator - Generate batches of tensor image data with real-time data augmentation.
datagen = ImageDataGenerator(
            rescale=1./255,
            fill_mode="constant", #filling up empty pixel space after rotation of image
            shear_range=0.2, #A transformation that slants the shape of an object, changes slope.
            zoom_range=(0.5, 1), #A random zoom is obtained by the zoom_range argument. A zoom less than 1.0 magnifies the image, while a zoom greater than 1.0 zooms out of the image.
            horizontal_flip=True,
            rotation_range=360,
            channel_shift_range=25,
            validation_split=0.25,
            brightness_range=(0.75, 1.25))

train_data_generator = datagen.flow_from_directory(
            IMG_DIRECTORY,
            target_size=IMG_SIZE,
            batch_size=BATCH_SIZE,
            #classes=CLASSES,
            subset="training")


val_data_generator = datagen.flow_from_directory(
            directory=IMG_DIRECTORY,
            target_size=IMG_SIZE,
            batch_size=BATCH_SIZE,
            #classes=CLASSES,
            subset="validation")

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('acc') > 0.99 and logs.get('val_acc') > 0.99):
            print("\nCancelling training as model has reached 99% accuracy and 99% validation accuracy!")
            self.model.stop_training = True

def crop(img, size):
    """
    Crop the image concentrically to the desired size.
    :param img: Input image
    :param size: Required crop image size
    :return:
    """
    (h, w, c) = img.shape
    x = int((w - size[0]) / 2)
    y = int((h - size[1]) / 2)
    return img[y:(y + size[1]), x:(x + size[0]), :]

def crop_generator(batches, size):
    """
    Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator
    :param batches: Batches of images to be cropped
    :param size: Size to be cropped to
    :return:
    """
    while True:
        batch_x, batch_y = next(batches)
        (b, h, w, c) = batch_x.shape
        batch_crops = np.zeros((b, size[0], size[1], c))
        for i in range(b):
            batch_crops[i] = crop(batch_x[i], (size[0], size[1]))
        yield (batch_crops, batch_y)

"""# Model"""

inputs = layers.Input(shape=INPUT_SHAPE)

x = layers.Conv2D(32, (2, 2), activation='relu')(inputs)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)

x = layers.Conv2D(32, (2, 2), activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)

x = layers.Conv2D(64, (2, 2), activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)

x = layers.Flatten()(x)

x = layers.Dense(1024, activation='relu')(x)
x = layers.Dropout(0.2)(x)

outputs = layers.Dense(4, activation='softmax')(x)

model = Model(inputs=inputs, outputs=outputs)

model.compile(optimizer=RMSprop(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""# **Inception V3**"""

# Download Inception v3 weights to local machine
!wget --no-check-certificate \
    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \
    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5

# Import Inception v3 Model
from tensorflow.keras.applications.inception_v3 import InceptionV3
pre_trained_model = InceptionV3(input_shape=(150, 150, 3), include_top=False, weights=None)

# Load Inception v3 weights into model
local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'
pre_trained_model.load_weights(local_weights_file)

for layer in pre_trained_model.layers:
    layer.trainable = False

# pre_trained_model.summary()
# plot_model(pre_trained_model, to_file='inception_v3_model.png', show_shapes=False, show_layer_names=True)

last_layer = pre_trained_model.get_layer('mixed7')
last_output = last_layer.output

x = layers.Flatten()(last_output)
x = layers.Dense(1024, activation='relu')(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(4, activation='softmax')(x)

model = Model(pre_trained_model.input, x)

model.compile(optimizer=RMSprop(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

callbacks = myCallback()
history = model.fit(train_data_generator,
                              validation_data=val_data_generator,
                              steps_per_epoch=100,
                              epochs=40,
                              validation_steps=100,
                              verbose=2)

model.save('/content/drive/MyDrive/weed_identification2.h5')



